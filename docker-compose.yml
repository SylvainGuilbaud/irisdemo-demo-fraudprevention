version: '3.7'

volumes:
  common_shared:

services:

  datalake:
    build: 
      context: ./normalized_datalake
    init: true
    image: ${DOCKER_REPOSITORY}:datalake-version-1.5.0
    hostname: datalake
    restart: on-failure
    ports:
    # 51773 is the superserver default port
    - "9095:51773"
    # 52773 is the webserver/management portal port
    - "9094:52773"
    volumes:
    - type: bind
      source: ./normalized_datalake/shared/
      target: /shared

  bankingcore:
    build: 
      context: ./banking_core
    init: true
    image: ${DOCKER_REPOSITORY}:bankingcore-version-1.5.0
    hostname: bankingcore
    ports:
    # 51773 is the superserver default port
    - "9091:51773"
    # 52773 is the webserver/management portal port
    - "9090:52773"
    volumes:
    - type: bind
      source: ./banking_core/shared/
      target: /shared

  bankingtrnsrv:
    build: 
      context: ./banking_trn_srv
    image: ${DOCKER_REPOSITORY}:bankingtrnsrv-version-1.5.0
    hostname: bankingtrnsrv
    init: true
    ports:
    # 51773 is the superserver default port
    - "9093:51773"
    # 52773 is the webserver/management portal port
    - "9092:52773"
    volumes:
    - common_shared:/common_shared   # The production will be looking into this folder for new PMML files
                                       # that will be sent by the advancedanalytics service.
    - type: bind
      source: ./banking_trn_srv/shared/
      target: /shared

  pos:
    build: ./pos
    image: ${DOCKER_REPOSITORY}:pos-version-1.5.0
    init: true
    ports:
      - "9099:4200"
    working_dir: /home/node/app
    environment:
      - NODE_ENV=production
      - OVERRID_BANKINGTRNSRV_HOST=
    command: "npm run proxy"

  advancedanalytics:
    image: intersystemsdc/irisdemo-base-zeppelin:${ZEPPELIN_IMAGE_VERSION}
    init: true
    ports:
    - "9096:9090"   # Zeppelin
    - 4141:4040     # Zeppelin Spark UI
    volumes:
    - common_shared:/common_shared   # The production will be looking into this folder for new PMML files
                                       # that will be sent by the advancedanalytics service.
    - type: bind
      source: ./advanced_analytics/shared/
      target: /shared
    environment:
    - IRIS_MASTER_HOST=datalake # DNS based on the name of the service!
    - IRIS_MASTER_PORT=51773 
    - IRIS_MASTER_USERNAME=SuperUser 
    - IRIS_MASTER_PASSWORD=sys 
    - IRIS_MASTER_NAMESPACE=APP 

  sparkmaster:
    image: intersystemsdc/irisdemo-base-spark-iris:${SPARK_IMAGE_VERSION}
    hostname: sparkmaster # Must be always sparkmaster
    init: true
    environment:
      SPARK_NODE_TYPE: Master
      SPARK_PUBLIC_DNS: localhost
      IRIS_MASTER_HOST: datalake # DNS based on the name of the service!
      IRIS_MASTER_PORT: 51773 
      IRIS_MASTER_USERNAME: SuperUser 
      IRIS_MASTER_PASSWORD: sys 
      IRIS_MASTER_NAMESPACE: APP 
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080   # Spark Master Portal
    volumes:
    - common_shared:/common_shared   # Shared between all spark nodes. Good place to place a file we are working with.

  worker1:
    depends_on: 
      - sparkmaster
    image: intersystemsdc/irisdemo-base-spark-iris:${SPARK_IMAGE_VERSION}
    hostname: worker1
    init: true
    environment:
      IRIS_MASTER_HOST: datalake # DNS based on the name of the service!
      IRIS_MASTER_PORT: 51773 
      IRIS_MASTER_USERNAME: SuperUser 
      IRIS_MASTER_PASSWORD: sys 
      IRIS_MASTER_NAMESPACE: APP 

      SPARK_NODE_TYPE: Worker
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 1g   # You can give more memory to your work if you are getting errors when using Spark
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    ports:
      - 8081:8081   # Spark Worker Portal
    volumes:
    - common_shared:/common_shared   # Shared between all spark nodes. Good place to place a file we are working with.  

  worker2:
    depends_on: 
      - sparkmaster
    image: intersystemsdc/irisdemo-base-spark-iris:${SPARK_IMAGE_VERSION}
    hostname: worker2
    init: true
    environment:
      IRIS_MASTER_HOST: datalake # DNS based on the name of the service!
      IRIS_MASTER_PORT: 51773 
      IRIS_MASTER_USERNAME: SuperUser 
      IRIS_MASTER_PASSWORD: sys 
      IRIS_MASTER_NAMESPACE: APP 

      SPARK_NODE_TYPE: Worker
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 1g   # You can give more memory to your work if you are getting errors when using Spark
      SPARK_WORKER_PORT: 8882
      SPARK_WORKER_WEBUI_PORT: 8082
      SPARK_PUBLIC_DNS: localhost
    ports:
      - 8082:8082   # Spark Worker Portal
    volumes:
    - common_shared:/common_shared   # Shared between all spark nodes. Good place to place a file we are working with.
